# 方法概览与改进建议

## 当前方法核心流程
- 以 `main.py` 为入口，将清洁图像归一化后交由 Stable Diffusion 2.0 的 VAE 编码至潜空间，并通过 `diff_latent_attack.py` 执行 DDIM 逆向扩散，获取逐步还原的潜变量序列。
- 在潜空间中对潜变量进行迭代优化，优化目标兼顾判别模型（`other_attacks.model_transfer`）的分类损失与注意力保持项，同时利用 `AttentionControlEdit` 监控交叉/自注意力权重，约束语义一致性。
- 调整 `--start_step`、`--iterations` 和掩模相关参数，结合伪掩模策略在像素空间保持结构，从而生成视觉上不可察觉但具备迁移性的对抗样本。
- 优化完成后将潜变量解码为图像，并通过日志与可视化工具 (`utils.view_images`) 输出扰动、原图与对抗结果。

## 关键模块与损失设计
- `AttentionControl` 系列类跟踪 U-Net 不同阶段的注意力图，使交叉注意力保持文本提示的语义对齐，自注意力保持自身结构稳定。
- `distances.LpDistance` 提供 Lp 范数约束，可限制潜变量偏移量；结合分类损失的加权求和形成多目标优化。
- `pytorch_fid` 下预存的 Inception 特征支持在评估阶段计算 FID 等感知指标，以衡量视觉质量。

## 现有瓶颈
- 依赖单一 surrogate 模型（默认 Inception 系列），对极端防御模型的迁移能力仍有限，且模型切换欠缺自动化配置。
- 固定的 DDIM 逆向与前向调度器在迭代次数有限时可能导致重建偏差，进而影响扰动与语义保真的平衡。
- 注意力正则主要基于 MSE，同一权重同时作用于所有层，难以区分不同尺度特征的重要性。
- 伪掩模与扰动约束未充分利用目标图像的结构信息，对细粒度数据集（如 CUB）可能出现局部过度扰动。
- 训练与评估流程对 GPU 显存需求高，缺乏自动混合精度与分布式策略，影响大规模实验效率。

## 潜在改进方向
- 设计多模型迁移策略：同时加载 `torch_nets` 中的多种防御模型，使用加权或最坏情况目标提升黑盒成功率，可结合模型不确定性自适应调整损失权重。
- 引入更先进的采样与逆扩散调度器（如 DPM-Solver++ 或 EDM）并自适应调节 `--start_step`，提高潜变量回溯精度，减少对高迭代次数的依赖。
- 对注意力损失做分层建模：依据层级或空间分辨率设置不同的权重，或将自注意力约束替换为 KL 散度、信息瓶颈等更稳定的度量。
- 结合感知与语义双重正则：加入 CLIP 或 LPIPS 距离，使扰动对高层语义更敏感，从而在保持可感知质量的同时提高攻击成功率。
- 构建自适应遮罩机制：利用显著性检测或梯度注意力生成动态掩模，限定扰动区域以更精准地操控关键语义内容。
- 优化工程性能：引入自动混合精度、梯度检查点与批量潜变量并行更新，缩短单次实验时间，为大规模超参数搜索提供基础。

## 新增优化方案：Prompt-to-Prompt 约束 + AdaEA 集成

本方案目标是在几乎不改变可感知结构的前提下显著提升黑盒迁移与成功率，核心由两部分组成：
- Prompt-to-Prompt（P2P）式注意力约束：在采样后段对跨注意力进行替换/插值，强约束构图与语义布局一致，变化集中于纹理与细节。
- 自适应集成分类损失（AdaEA）：聚合多分类器梯度并自适应加权，强化有效方向、抑制冲突，提升迁移性与稳定性。

### P2P 约束要点与落点
- 层与时间调度：
  - 时间：在后段步（如 50 步中的最后 30%）加大替换比例；早期步仅轻约束，避免锁死优化空间。
  - 层级：对高层 block（结构/布局）强约束，对低层（纹理）放松；跨注意力约束强于自注意力。
- 替换/插值策略：
  - 未编辑 token 完全替换（keep=1.0）；编辑 token 线性插值 `A ← (1-α)A + αA_ref`，α≈0.2–0.5。
  - 可额外加入注意力一致性项 `L_attn = ||A_t − A_ref||_1`（仅对非编辑 token），权重小（λ_attn≈0.05–0.2）。
- 噪声对齐：源/编辑过程共享初始噪声与调度器，保证可控编辑成立。
- 代码落点：
  - 交叉注意力钩子位于 `diff_latent_attack.py:register_attention_control` 与 `aggregate_attention` 调用处，采样循环与注意力汇聚在 `diff_latent_attack.py:560` 附近可获取 `before/after` 注意力张量用于损失。
  - 旧的方差正则（`after_true_label_attention_map.var()`）可替换为熵正则或 P2P 替换/对比项（详见 `LOSS_OPTIMIZATION.md`）。

### AdaEA 集成要点与落点
- 目标函数：
  - 无目标攻击：最小化 margin `L_i = logit_true − max_{k≠true} logit_k`，或 CW 型；目标攻击则最大化目标类 margin。
- 动态权重：
  - 梯度归一：`g_i ← g_i / ||g_i||_2`；
  - 相似度加权：`s_i = cos(g_i, g_ens)`，`w_i ∝ softmax(τ·s_i)`，τ≈5–10；或按最近若干步的 margin 改善量做 softmax；
  - 动量融合：μ≈0.9 的动量 PGD/Nesterov；对总梯度作 `clip_grad_norm_` 防爆。
- EOT 稳健性：引入轻量随机旋转/缩放/色偏的期望梯度，隔步计算以控算力。
- 代码落点：
  - 单模型调用位于 `diff_latent_attack.py:381`（`classifier = other_attacks.model_selection(model_name).eval()`）和 `diff_latent_attack.py:592` 的前向与损失计算处；将其替换为多模型前向并在损失处做加权聚合。

### 总损失与调度建议
- 联合目标：`L_total = λ_cls·L_cls_ens + λ_lpips·LPIPS(x,x0) + λ_l2·||x−x0||_2^2 [+ λ_attn·L_attn]`
- 推荐初值：`λ_cls=1.0, λ_lpips=0.2–0.5, λ_l2=1e−4–5e−4, λ_attn=0.05–0.2`；
- 步间注入：在后 40–60% 采样步注入分类梯度，每 1–2 步一次；早期以 P2P 保形为主，`λ_cls` 随步递增。
- 更新域：优先在潜空间 z 优化，VAE 解码至像素后再过分类器求梯度，链式回传至 z。

### 最小改动实施清单（指导编码）
- 注意力约束：
  - 在 `diff_latent_attack.py:560` 附近，用 P2P 的替换/插值和熵正则替换 `variance_cross_attn_loss`；保留自注意力结构项 `controller.loss`。
- 集成损失：
  - 在 `diff_latent_attack.py:381` 将单一 `classifier` 改为模型列表，并在损失处实现 AdaEA 加权；维持接口 `--model_name` 兼容，新增 `--ensemble` 列表与 `--adaea_tau`、`--eot` 参数（文档先行，代码后补）。
- 调度：
  - 在采样循环中按 step 比例线性/余弦调整各损失权重；仅在中高层与后段步启用 P2P 替换/对比项。

> 详细的损失公式、伪代码与超参建议参见 `LOSS_OPTIMIZATION.md` 中新增章节。
